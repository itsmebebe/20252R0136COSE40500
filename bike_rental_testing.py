# -*- coding: utf-8 -*-
"""Bike_Rental_testing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10ZFr1p04IrBhxtVEMJMUzj4ETZwab_Ya
"""

# Importing necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error

# Load the dataset
df=pd.read_csv('바이크 렌탈 데이터 (1~9710).csv')


# 'datetime'에서 'hour' 열을 생성
df['datetime'] = pd.to_datetime(df['datetime'])
df['hour'] = df['datetime'].dt.hour
df['month'] = df['datetime'].dt.month
df.loc[df['weather'] == 4, 'weather'] = 3
df['temp_atemp_avg'] = (df['temp'] + df['atemp']) / 2


# 'hour' 열을 이용해 'time_of_day'를 적용
def time_of_day(hour):
    if 0 <= hour < 6:
        return '1'       # 새벽
    elif 6 <= hour < 10:
        return '2'    # 아침
    elif 10 <= hour < 17:
        return '3'  # 낮
    elif 17 <= hour < 21:
        return '4'    # 저녁
    else:
        return '5'      # 밤

df['time_of_day'] = df['hour'].apply(time_of_day).astype(int)

# Hour
df['hour'] = df['datetime'].dt.hour
df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)

# Day of Week
df['day_of_week'] = df['datetime'].dt.dayofweek
df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)


df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
df['summer'] = np.where((df['month'] >= 4) & (df['month'] <= 8), 1, 0)
df['year']=df['datetime'].dt.year

# Interaction Features (weather-related)
df['temp_humidity_interaction'] = df['temp'] * df['humidity']
df['season_weather'] = df['season'] * df['weather']


categorical_col=["season","workingday","weather","day_of_week","holiday","year","summer"]
numerical_col=["temp_atemp_avg","hour_sin","hour_cos","humidity","month_sin","month_cos",
               "windspeed","temp_humidity_interaction"]
target_col=["count"]



X_train=df[categorical_col+numerical_col]
y_train=df[target_col]
#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Load the dataset
df2=pd.read_csv('test_with_count.csv')

df2.loc[df2['weather'] == 4, 'weather'] = 3
df2['temp_atemp_avg'] = (df2['temp'] + df2['atemp']) / 2

# 'datetime'에서 'hour' 열을 생성
df2['datetime'] = pd.to_datetime(df2['datetime'])
df2['hour'] = df2['datetime'].dt.hour

# 'hour' 열을 이용해 'time_of_day'를 적용
def time_of_day(hour):
    if 0 <= hour < 6:
        return '1'       # 새벽
    elif 6 <= hour < 10:
        return '2'    # 아침
    elif 10 <= hour < 17:
        return '3'  # 낮
    elif 17 <= hour < 21:
        return '4'    # 저녁
    else:
        return '5'      # 밤

df2['time_of_day'] = df2['hour'].apply(time_of_day).astype(int)

# Hour
df2['hour'] = df2['datetime'].dt.hour
df2['hour_sin'] = np.sin(2 * np.pi * df2['hour'] / 24)
df2['hour_cos'] = np.cos(2 * np.pi * df2['hour'] / 24)

# Day of Week
df2['day_of_week'] = df2['datetime'].dt.dayofweek
df2['day_of_week_sin'] = np.sin(2 * np.pi * df2['day_of_week'] / 7)
df2['day_of_week_cos'] = np.cos(2 * np.pi * df2['day_of_week'] / 7)


# Month
df2['month'] = df2['datetime'].dt.month
df2['month_sin'] = np.sin(2 * np.pi * df2['month'] / 12)
df2['month_cos'] = np.cos(2 * np.pi * df2['month'] / 12)
df2['summer'] = np.where((df2['month'] >= 4) & (df2['month'] <= 8), 1, 0)
df2['year']=df2['datetime'].dt.year

# Interaction Features (weather-related)
df2['temp_humidity_interaction'] = df2['temp'] * df2['humidity']
df2['season_weather'] = df2['season'] * df2['weather']


categorical_col=["season","workingday","summer","weather","day_of_week","holiday","year"]
numerical_col=["temp_atemp_avg","hour_sin","hour_cos","humidity","month_sin","month_cos",
               "windspeed","temp_humidity_interaction"]
target_col=["count"]

X_val=df2[categorical_col+numerical_col]
y_val=df2[target_col]

prepocessor=ColumnTransformer(
    transformers=[('num',StandardScaler(),numerical_col),
        ('cat',OneHotEncoder(),categorical_col)
        ],
        remainder='passthrough'
  )

model_pipeline=Pipeline(
    steps=[
        ('preprocessor',prepocessor),
        ('regressor',RandomForestRegressor(max_depth= 19, min_samples_split=4,n_estimators=150,random_state=42))
    ]
)
#model_pipeline.fit(X_resampled, y_resampled)
model_pipeline.fit(X_train, y_train)
y_pred=model_pipeline.predict(X_val)

y_pred_clipped = np.clip(y_pred, 0, 800)
mse_clipped = mean_squared_error(y_val, y_pred_clipped)
print("Clipped MSE:", mse_clipped)

mse=mean_squared_error(y_val,y_pred.round())
print(mse)

"""4748.721117678668"""

import pandas as pd

# Assuming y_pred is your predictions array or list
# Convert the predictions to a DataFrame
predictions_df = pd.DataFrame({'Predicted Count': y_pred_clipped})

# Save the DataFrame to an Excel file
predictions_df.to_excel('predicted_counts_real.xlsx', index=False)

print("Predicted counts have been saved to 'predicted_counts.xlsx'")

"""#번외 방법"""

import pandas as pd

# Convert y_pred from a 2D array to a 1D array
y_pred = y_pred.flatten()

# Create a DataFrame with the datetime and predicted count values
predictions_df = pd.DataFrame({
    'datetime': df2['datetime'],  # Assuming df2 has the datetime column
    'predicted_count': y_pred
})

# Save to Excel or CSV
predictions_df.to_excel('predicted_counts.xlsx', index=False)  # To save as Excel
# Or, use this line to save as CSV
# predictions_df.to_csv('predicted_counts.csv', index=False)

print("Predicted counts have been saved as 'predicted_counts.xlsx'")

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense
from sklearn.metrics import mean_squared_error

# Assuming X_train, y_train, X_val, and y_val are defined as in your code

# Normalize the numerical features
scaler = StandardScaler()
X_train[numerical_col] = scaler.fit_transform(X_train[numerical_col])
X_val[numerical_col] = scaler.transform(X_val[numerical_col])

# Convert the data to numpy arrays
X_train = X_train.values
y_train = y_train.values
X_val = X_val.values
y_val = y_val.values

# Reshape data for GRU (samples, time steps, features)
# Here, we assume each sample represents a single time step (e.g., each row is independent)
# You might also consider aggregating data into sequences if there’s a time-dependent relationship
X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))

# Define the GRU model
model = Sequential()
model.add(GRU(units=50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dense(1))  # Output layer for regression

model.compile(optimizer='adam', loss='mse')

# Train the model
history = model.fit(X_train, y_train, epochs=14, batch_size=32, validation_data=(X_val, y_val), verbose=1)

# Make predictions on the validation set
y_pred = model.predict(X_val)

# Calculate the Mean Squared Error
mse = mean_squared_error(y_val, y_pred)
print("GRU Model - Validation MSE:", mse)

# Simple Model: Linear Regression
linear_model = Pipeline([
    ('scaler', StandardScaler()),
    ('regressor', LinearRegression())
])

# Train and evaluate the Linear Regression model
linear_model.fit(X_train, y_train)
y_pred_train = linear_model.predict(X_train)
y_pred_val = linear_model.predict(X_val)

print("Linear Regression - Training MSE:", mean_squared_error(y_train, y_pred_train))
print("Linear Regression - Validation MSE:", mean_squared_error(y_val, y_pred_val))

# Complex Model: Random Forest
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_train_rf = rf_model.predict(X_train)
y_pred_val_rf = rf_model.predict(X_val)

print("Random Forest - Training MSE:", mean_squared_error(y_train, y_pred_train_rf))
print("Random Forest - Validation MSE:", mean_squared_error(y_val, y_pred_val_rf))

# Complex Model: Gradient Boosting
gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
gb_model.fit(X_train, y_train)
y_pred_train_gb = gb_model.predict(X_train)
y_pred_val_gb = gb_model.predict(X_val)

print("Gradient Boosting - Training MSE:", mean_squared_error(y_train, y_pred_train_gb))
print("Gradient Boosting - Validation MSE:", mean_squared_error(y_val, y_pred_val_gb))

# For other feature engineering, interaction terms or advanced scaling methods can be added